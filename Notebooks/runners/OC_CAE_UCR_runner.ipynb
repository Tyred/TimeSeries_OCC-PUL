{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OC_CAE_UCR-runner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyred/TimeSeries_OCC-PUL/blob/main/Notebooks/runners/OC_CAE_UCR_runner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kff21qy6oEe7"
      },
      "source": [
        "<h1> One-Class Classification Using Convolutional Autoencoders </h1>\n",
        "\n",
        "The main idea is to train a CAE (Convolutional Autoencoder) with data from the positive class only and calculate a reconstruction error threshold T based on the reconstruction errors obtained during the training. <br/>\n",
        "Then we perform the One-Class Classification (OCC) as follows:\n",
        "\n",
        "- For each data sample in the test dataset, do:\n",
        "    - Reconstruct the data with the CAE and calculate its reconstruction error E.\n",
        "    - if E <= T the sample is classified as a member of the positive class.\n",
        "    - else (if E > T) the sample is classified as not a member of the positive class.  \n",
        "\n",
        "- Evaluate the Model's Accuracy, Precision and Recall."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OflopftEPi5L"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2XDcHByvEwN"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
        "                            roc_auc_score)\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePSM72bBkX6x"
      },
      "source": [
        "# Autoencoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kwmDiXclBaQ"
      },
      "source": [
        "## Convolutional Using MaxPooling\n",
        "- Subclassing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7j4Lk7QQxa6P"
      },
      "source": [
        "# Convolutional Autoencoder with MaxPooling:\n",
        "class ConvAutoencoder(tf.keras.Model):\n",
        "    def __init__(self, serie_length): #, serie_length):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        self.conv_1  = keras.layers.Conv1D(32, 3, activation='swish', padding='causal') #, input_shape=(serie_length))\n",
        "        self.max_1   = keras.layers.MaxPooling1D(2)\n",
        "        self.conv_2  = keras.layers.Conv1D(64, 3, activation='swish', padding='causal')\n",
        "        self.max_2   = keras.layers.MaxPooling1D(2)\n",
        "        self.conv_3  = keras.layers.Conv1D(128, 3, activation='swish', padding='causal')\n",
        "        \n",
        "        # encoded representation\n",
        "        self.encoded = keras.layers.MaxPooling1D(2)\n",
        "        \n",
        "        # decoder layers\n",
        "        self.conv_4  = keras.layers.Conv1D(128, 3, activation='swish', padding='causal')\n",
        "        self.up_1    = keras.layers.UpSampling1D(2)\n",
        "        self.conv_5  = keras.layers.Conv1D(64, 3, activation='swish', padding='causal')\n",
        "        self.up_2    = keras.layers.UpSampling1D(2)\n",
        "        self.conv_6  = keras.layers.Conv1D(32, 3, activation='swish', padding='causal')\n",
        "        self.up_3    = keras.layers.UpSampling1D(2)\n",
        "        \n",
        "        #self.flt     = keras.layers.Flatten()\n",
        "        \n",
        "        # decoded output\n",
        "        self.decoded = keras.layers.Conv1D(1, 3, activation='linear', padding='causal')\n",
        "        #self.decoded = keras.layers.Dense(serie_length, activation='linear')\n",
        "        \n",
        "    def encoder(self, inputs):\n",
        "        if self.padding != 0:\n",
        "            inputs = keras.layers.ZeroPadding1D(padding=(8 + 8-self.padding, 0))(inputs)\n",
        "        x = self.conv_1(inputs)\n",
        "        x = self.max_1(x)\n",
        "        x = self.conv_2(x)\n",
        "        x = self.max_2(x)\n",
        "        x = self.conv_3(x)\n",
        "        return self.encoded(x)\n",
        "    \n",
        "    def decoder(self, inputs):\n",
        "        #x = self.encode(inputs)\n",
        "        x = self.conv_4(inputs)\n",
        "        x = self.up_1(x)\n",
        "        x = self.conv_5(x)\n",
        "        x = self.up_2(x)\n",
        "        x = self.conv_6(x)\n",
        "        x = self.up_3(x)\n",
        "        \n",
        "        #x = self.flt(x)\n",
        "        \n",
        "        if self.padding != 0:\n",
        "            x = keras.layers.Cropping1D(cropping=(8 + 8-self.padding, 0))(x)\n",
        "        \n",
        "        return self.decoded(x)\n",
        "        \n",
        "        \n",
        "    def call(self, inputs):\n",
        "        self.padding = inputs.shape[1] % 8\n",
        "        _encoded = self.encoder(inputs)\n",
        "        _decoded = self.decoder(_encoded)\n",
        "\n",
        "        return _decoded\n",
        "\n",
        "    def model(self):\n",
        "        x = keras.layers.Input(shape=(serie_length, 1))\n",
        "        return tf.keras.Model(inputs=[x], outputs=self.call(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OCC Functions"
      ],
      "metadata": {
        "id": "CWF9Lg4PPQ3J"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgNdWKXXT5Hl"
      },
      "source": [
        "def predict(model, data, threshold):\n",
        "    reconstructions = model(data)\n",
        "    reconstructions = reconstructions.numpy().squeeze()\n",
        "    data = data.numpy().squeeze()\n",
        "    loss = tf.keras.losses.mse(reconstructions, data)\n",
        "    return tf.math.less_equal(loss, threshold)\n",
        "\n",
        "def print_stats(predictions, labels):\n",
        "    print(\"Accuracy = %.2f\"  % (accuracy_score(labels, predictions)  *100) + \"%\")\n",
        "    print(\"Precision = %.2f\" % (precision_score(labels, predictions) *100) + \"%\")\n",
        "    print(\"Recall = %.2f\"    % (recall_score(labels, predictions)    *100) + \"%\")\n",
        "    print(\"F1-Score = %.2f\"  % (f1_score(labels, predictions)        *100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad-D4CADlFDa"
      },
      "source": [
        "# UCR Binary Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTl7TYPJv8LK"
      },
      "source": [
        "datasets = ['Yoga', 'WormsTwoClass', 'Wine', 'Wafer', 'TwoLeadECG', 'Strawberry', 'SemgHandGenderCh2', \n",
        "            'BeetleFly', 'BirdChicken', 'Computers', 'DistalPhalanxOutlineCorrect', 'Earthquakes',\n",
        "            'ECG200', 'ECGFiveDays', 'FordA', 'FordB', 'HandOutlines', 'ItalyPowerDemand', \n",
        "            'MiddlePhalanxOutlineCorrect', 'Chinatown', 'FreezerRegularTrain', 'FreezerSmallTrain',\n",
        "            'GunPointAgeSpan', 'GunPointMaleVersusFemale', 'GunPointOldVersusYoung', 'PowerCons', 'Coffee',\n",
        "            'Ham', 'Herring', 'Lightning2', 'MoteStrain', 'PhalangesOutlinesCorrect', 'ProximalPhalanxOutlineCorrect',\n",
        "            'ShapeletSim', 'SonyAIBORobotSurface1', 'SonyAIBORobotSurface2', 'ToeSegmentation1', 'ToeSegmentation2',\n",
        "            'HouseTwenty']\n",
        "\n",
        "path = 'drive/My Drive/UFSCar/FAPESP/IC/Data/UCRArchive_2018'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dataset in datasets:\n",
        "    tr_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TRAIN.tsv\", \n",
        "                            delimiter=\"\\t\",)\n",
        "    te_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TEST.tsv\", \n",
        "                            delimiter=\"\\t\",)\n",
        "\n",
        "    labels = te_data[:, 0]\n",
        "    #print(\"Labels:\", np.unique(labels))\n",
        "    unique_labels = np.unique(labels)\n",
        "    for class_label in unique_labels:\n",
        "        train_data  = tr_data[tr_data[:, 0] == class_label, 1:] # train\n",
        "        test_data   = te_data[:, 1:]                            # test\n",
        "        #print(\"Train data shape:\", train_data.shape)\n",
        "        #print(\"Test data shape:\", test_data.shape)\n",
        "\n",
        "        train_data = tf.cast(train_data, tf.float32)\n",
        "        test_data  = tf.cast(test_data , tf.float32)\n",
        "\n",
        "        train_data = tf.expand_dims(train_data, axis=-1)\n",
        "        test_data  = tf.expand_dims(test_data , axis=-1)\n",
        "\n",
        "        serie_length = train_data.shape[1]\n",
        "\n",
        "        occ_labels = [1 if x == class_label else 0 for x in labels]\n",
        "        #print(\"Positive samples:\", occ_labels.count(1))\n",
        "        #print(\"Negative samples:\", occ_labels.count(0))\n",
        "        \n",
        "        # Labeling for OCC\n",
        "        positive_test_data = test_data[np.array(occ_labels).astype(bool)]\n",
        "        negative_test_data = test_data[~np.array(occ_labels).astype(bool)]\n",
        "\n",
        "        # Autoencoder\n",
        "        autoencoder = ConvAutoencoder(train_data.shape[1]) \n",
        "        autoencoder.compile(optimizer='adam', loss='mse') \n",
        "\n",
        "        # Train\n",
        "        batch_size = 32\n",
        "        epochs = 200\n",
        "\n",
        "        my_callbacks = [\n",
        "            tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss')\n",
        "        ]\n",
        "\n",
        "        history = autoencoder.fit(train_data, train_data, \n",
        "                epochs=epochs, \n",
        "                batch_size=batch_size,\n",
        "                validation_data=(test_data, test_data),\n",
        "                callbacks=my_callbacks,\n",
        "                verbose=0)\n",
        "\n",
        "        # OCC Task\n",
        "        reconstructions = autoencoder.predict(train_data).squeeze()\n",
        "        train_loss = tf.keras.losses.mse(reconstructions, train_data.numpy().squeeze())\n",
        "        \n",
        "        sigma_list = [2] # chosen empirically\n",
        "        mean = np.mean(train_loss)\n",
        "        stddev = np.std(train_loss)\n",
        "\n",
        "        for sigma in sigma_list:\n",
        "            threshold = mean + sigma*stddev\n",
        "            print(\"Dataset:\", dataset, \"Positive Label:\", class_label)\n",
        "            preds = predict(autoencoder, test_data, threshold)\n",
        "            print_stats(preds, occ_labels)\n",
        "            print()"
      ],
      "metadata": {
        "id": "fGzZPB8ROPgm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}