{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OC-SVM.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1MzheYjB3Q5jiFr1Pinw1EYg-TcBTazjF",
      "authorship_tag": "ABX9TyPtBlbR6KDkl2UMpu0aFqGe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyred/TimeSeries_OCC-PUL/blob/main/Notebooks/OC_SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emi8F7ZFdSrK"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnoW8j3yNpuZ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.svm import OneClassSVM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6y-sBkgCb8GM"
      },
      "source": [
        "## Reading the dataset from Google Drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn5JbVRONu1T"
      },
      "source": [
        "path = 'drive/My Drive/UFSCar/FAPESP/IC/Data/UCRArchive_2018'\n",
        "\n",
        "dataset = input('Dataset: ')\n",
        "tr_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TRAIN.tsv\", delimiter=\"\\t\",)\n",
        "te_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TEST.tsv\", delimiter=\"\\t\",)\n",
        "\n",
        "labels      = te_data[:, 0]                             # labels\n",
        "print(\"Labels:\", np.unique(labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0l2RpHUcHaB"
      },
      "source": [
        "## Splitting in Train-Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLaE6_vANwQL"
      },
      "source": [
        "class_label = int(input('Positive class label: '))\n",
        "\n",
        "train_data  = tr_data[tr_data[:, 0] == class_label, 1:] # train\n",
        "test_data   = te_data[:, 1:]                            # test\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcC1Ru1McR5b"
      },
      "source": [
        "## Labeling for OCC Task\n",
        "<li> Label 1 for positive class </li>\n",
        "<li> Label -1 for other class(es) </li>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEFEYrdWOHl_"
      },
      "source": [
        "pseudo_labels = [1 if x == class_label else -1 for x in labels]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bhO6UkmchYB"
      },
      "source": [
        "## OC-SVM Fitting "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7U2LY8YPbLW"
      },
      "source": [
        "clf = OneClassSVM(gamma='scale').fit(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TESEcsVUcyyH"
      },
      "source": [
        "## Evaluation Function (Accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSLLhO9Mcvsj"
      },
      "source": [
        "def Evaluate(true_labels, test_labels): # Evaluate Accuracy\n",
        "  return np.count_nonzero(true_labels == test_labels)/len(true_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuia1i6pc63Q"
      },
      "source": [
        "## Testing and Evaluating Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXfI9NmGQKAw"
      },
      "source": [
        "result_labels = clf.predict(test_data)\n",
        "\n",
        "print(\"Accuracy: %.2f\" % (Evaluate(pseudo_labels, result_labels) * 100) + \"%\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}