{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OC-JKNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "17eRNOj67rNC589ROr7y2eD1nWOLVDGh2",
      "authorship_tag": "ABX9TyO92PvL8K9DnacoRC1yZ1q1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tyred/TimeSeries_OCC-PUL/blob/main/Notebooks/OC_JKNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fPFGm55KXt5p"
      },
      "source": [
        "<h1> One-Class J-K Nearest Neighbor Classifier</h1>\n",
        "The main idea is to fit a KNN classifier with data from the positive class only and then perform the OCC as follows [1]:\n",
        "\n",
        "- For each data sample in the test dataset, do:\n",
        "    - Compute the distance to its J nearest neighbours and find their average D_j\n",
        "    - Compute the distance of each J nearest neighbor to its K nearest neighbours and find their average D_k\n",
        "    - if D_j/D_k <= T then the test sample is classified as a member of the positive class.\n",
        "    - else the test sample is classified as not a member of the positive class.\n",
        "\n",
        "- Evaluate the Model's Accuracy, Precision and Recall.\n",
        "\n",
        "We have 3 hyperparameters, K, J and T. The classifier performance may vary a lot with differents values of these hyperparameters. Initially we will use the value 1 for each hyperparameter just for a proof-of-concept. Later we will develop a Parameter Optimization technique.\n",
        "\n",
        "[1] [Relationship between Variants of One-Class Nearest\n",
        "Neighbours and Creating their Accurate Ensembles](https://arxiv.org/abs/1604.01686)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyhZZAMcsEu8"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaTKHB_qtT-i"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from fastdtw import fastdtw\n",
        "from scipy.spatial.distance import euclidean"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VvQZvdwUyoQ"
      },
      "source": [
        "# OneClassJKNN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6aUHkPI_kQV"
      },
      "source": [
        "class OneClassJKNN():\n",
        "    \n",
        "    def __init__(self, j, k): # j, k >= 1\n",
        "        self.j = j\n",
        "        self.k = k\n",
        "\n",
        "        self.nbrs = NearestNeighbors(n_neighbors=self.k+1)\n",
        "\n",
        "    def fit(self, train_data):\n",
        "        self.nbrs.fit(train_data)\n",
        "        distances, indices = self.nbrs.kneighbors(train_data)\n",
        "\n",
        "        self.distances_avg = []\n",
        "        for sample in distances:\n",
        "            avg = np.mean(sample[1:])\n",
        "            self.distances_avg.append(avg)\n",
        "        \n",
        "        return self\n",
        "\n",
        "    def predict(self, test_samples, threshold):\n",
        "        predictions = np.zeros(len(test_samples))\n",
        "        sample_no = 0\n",
        "        for test_sample in test_samples:\n",
        "            distances, indices = self.nbrs.kneighbors(test_sample.reshape(1,-1), self.j)\n",
        "            jnbrs_avg = np.mean(distances)\n",
        "            \n",
        "            j_knbrs_sum = 0\n",
        "            for idx in indices[0]:\n",
        "                j_knbrs_sum += self.distances_avg[idx]\n",
        "            \n",
        "            j_knbrs_avg = j_knbrs_sum/self.j\n",
        "\n",
        "            if jnbrs_avg <= (j_knbrs_avg * threshold):\n",
        "                predictions[sample_no] = 1\n",
        "            else:\n",
        "                predictions[sample_no] = -1\n",
        "            \n",
        "            sample_no += 1\n",
        "\n",
        "        return predictions"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reports function"
      ],
      "metadata": {
        "id": "tXthW_J2rppB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stats(predictions, labels):\n",
        "    print(\"Accuracy = %.2f\"  % (accuracy_score(labels, predictions)  *100) + \"%\")\n",
        "    print(\"Precision = %.2f\" % (precision_score(labels, predictions) *100) + \"%\")\n",
        "    print(\"Recall = %.2f\"    % (recall_score(labels, predictions)    *100) + \"%\")\n",
        "    print(\"F1-Score = %.2f\"  % (f1_score(labels, predictions)        *100) + \"%\")"
      ],
      "metadata": {
        "id": "i176N2udrteM"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmnelSyqsHWd"
      },
      "source": [
        "# Reading Data from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSNSL41pyFfq",
        "outputId": "74a42906-da92-456e-b72b-1ba629493697"
      },
      "source": [
        "path = 'drive/My Drive/UFSCar/FAPESP/IC/Data/UCRArchive_2018'\n",
        "\n",
        "dataset = input('Dataset: ')\n",
        "tr_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TRAIN.tsv\", delimiter=\"\\t\",)\n",
        "te_data = np.genfromtxt(path + \"/\" + dataset + \"/\" + dataset + \"_TEST.tsv\", delimiter=\"\\t\",)\n",
        "\n",
        "labels = te_data[:, 0]\n",
        "print(\"Labels:\", np.unique(labels))"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset: Yoga\n",
            "Labels: [1. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Weh6yolnsMg6"
      },
      "source": [
        "# Choosing the Positive Class label\n",
        "This is necessary in order to emulate the One-Class Classification scenario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hUFkgobkVBf9",
        "outputId": "a9bb1398-dba6-4d8c-d436-85a6149f8e0a"
      },
      "source": [
        "class_label = int(input('Positive class label: '))\n",
        "\n",
        "train_data  = tr_data[tr_data[:, 0] == class_label, 1:] # train\n",
        "test_data   = te_data[:, 1:]                            # test\n",
        "\n",
        "print(\"Train data shape:\", train_data.shape)\n",
        "print(\"Test data shape:\", test_data.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive class label: 2\n",
            "Train data shape: (163, 426)\n",
            "Test data shape: (3000, 426)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Labeling for OCC Task"
      ],
      "metadata": {
        "id": "OkliUuLRrfxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "occ_labels = [1 if x == class_label else -1 for x in labels]\n",
        "print(\"Positive samples:\", occ_labels.count(1))\n",
        "print(\"Negative samples:\", occ_labels.count(-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWyECLp4rex4",
        "outputId": "f2f0f541-4207-4570-f79f-c93322d7b50e"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive samples: 1607\n",
            "Negative samples: 1393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Results"
      ],
      "metadata": {
        "id": "vPHrnm7SrwWF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "j = 2\n",
        "k = 5\n",
        "threshold = 1.5"
      ],
      "metadata": {
        "id": "Zzx-Ap57u1V6"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = OneClassJKNN(j, k).fit(train_data)\n",
        "\n",
        "result_labels = clf.predict(test_data, threshold)\n",
        "\n",
        "print_stats(result_labels, occ_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zk5IAkNQri4K",
        "outputId": "2e765ff3-480b-4c1a-ee2d-276ba0162621"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 61.97%\n",
            "Precision = 59.19%\n",
            "Recall = 93.34%\n",
            "F1-Score = 72.45%\n"
          ]
        }
      ]
    }
  ]
}